{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "For Milestone 1 you should generate a roughly 1 page writeup (~500 words) listing a partner and one to three datasets that you are considering working with and why. For each dataset you should generate at least one question you hope to answer with that data as well as a small amount of ETL including one interesting stat and one graph. This is just an outline to make sure you are thinking and is not a commitment in any way. This will be published on your GitHub IO page so this also makes sure you’ve figured out how to get it uploaded!\n",
        "\n",
        "You must also include a short collaboration plan describing how you are working together, what technologies you are using, and when / how often you are meeting to work on this project. Examples include: we setup a private Github repo to coordinate code and we met on Zoom X times…. or even we used LiveShare for CS Code Teletype for Atom or RemoteCollab for Sublime. Failure to turn in a collaboration plan that shows you coordinated will be a loss of professionalism points. The turned in result will need to reflect the understanding of both students\n",
        "\n",
        "You should load one of these datasets and parse it into shape using the principles of tidy data discussed in class and display the data table in a reasonable format so demonstrating what data you have. This is to show that you have figured out how to get the data into your system and does not need to be a final version, but it should show that you can read in a data source for your project. You should clearly discuss the data and what challenges you had in formatting it.\n",
        "\n",
        "One page Writeup (500 words)\n",
        "For each dataset, generate one or more questions you hope as well as some ETL including one interesting stat and one graph.\n",
        "Short collaboration plan:\n",
        "How we are working togther, what technologies wer\n",
        "\n"
      ],
      "metadata": {
        "id": "zdJ2EkSkIeet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   One page Writeup (500 words)\n",
        "*   For each dataset, generate one or more questions you hope as well as some ETL including one interesting stat and one graph. \n",
        "\n",
        "\n",
        "*   Short collaboration plan: \n",
        "  *   How we are working togther, what technologies wer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vLaVnpS0IiAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Where Does Foreign Aid Go?\n",
        "By Chris Callahan and Mikey Sison"
      ],
      "metadata": {
        "id": "jL14LN0OEFYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets Used for Project: \n",
        "[Gapminder](https://www.gapminder.org/data/), \n",
        "[US Gov Foreign Assistance](https://foreignassistance.gov/\n",
        ")"
      ],
      "metadata": {
        "id": "uOgrhIxyDvmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone "
      ],
      "metadata": {
        "id": "g1Hw5PvpP9U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install geopandas"
      ],
      "metadata": {
        "id": "-TE_UtBMMnGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## IMPORTS ##\n",
        "\n",
        "# Load Numpy\n",
        "import numpy as np\n",
        "\n",
        "# Load Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Load MatPlotLib\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Seaborn\n",
        "import seaborn as sns; sns.set_theme()\n",
        "\n"
      ],
      "metadata": {
        "id": "yOYDRMt3JSE6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ETL Analysis"
      ],
      "metadata": {
        "id": "owNeCARMMu9G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6qSdpAzMuIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5xaj12YL9Fn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}